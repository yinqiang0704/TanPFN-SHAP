{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbf5581-b0f5-43d2-9b17-58a666754679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "åŠ è½½æ•°æ®\n",
      "============================================================\n",
      "âœ“ æˆåŠŸåŠ è½½æ•°æ®: tabpfn_dataset_1000.xlsx\n",
      "æ•°æ®å½¢çŠ¶: (1000, 15)\n",
      "åˆ—å: ['age', 'experience_level', 'learning_style', 'category', 'difficulty_level', 'ratings', 'num_reviews', 'time_spent_on_course', 'completion_status', 'video_topic', 'video_duration', 'time_watched', 'skip_count', 'pause_count', 'engagement_score']\n",
      "\n",
      "============================================================\n",
      "å¤šé‡å…±çº¿æ€§æ£€éªŒ (VIFåˆ†æ)\n",
      "============================================================\n",
      "è®¡ç®—æ–¹å·®è†¨èƒ€å› å­(VIF)...\n",
      "\n",
      "ğŸ“Š VIFåˆ†æç»“æœ:\n",
      "--------------------------------------------------------------------------------\n",
      "             Feature      VIF       Collinearity_Level Collinearity_Concern\n",
      "        time_watched 3.231421 Acceptable (1 < VIF < 5)                  LOW\n",
      "      video_duration 2.570890 Acceptable (1 < VIF < 5)                  LOW\n",
      "   completion_status 1.839622 Acceptable (1 < VIF < 5)                  LOW\n",
      "         num_reviews 1.431341 Acceptable (1 < VIF < 5)                  LOW\n",
      "             ratings 1.360485 Acceptable (1 < VIF < 5)                  LOW\n",
      "          skip_count 1.227318 Acceptable (1 < VIF < 5)                  LOW\n",
      "time_spent_on_course 1.122641 Acceptable (1 < VIF < 5)                  LOW\n",
      "         pause_count 1.085053 Acceptable (1 < VIF < 5)                  LOW\n",
      "    difficulty_level 1.053342 Acceptable (1 < VIF < 5)                  LOW\n",
      "    experience_level 1.051746 Acceptable (1 < VIF < 5)                  LOW\n",
      "      learning_style 1.032792 Acceptable (1 < VIF < 5)                  LOW\n",
      "            category 1.013897 Acceptable (1 < VIF < 5)                  LOW\n",
      "                 age 1.013868 Acceptable (1 < VIF < 5)                  LOW\n",
      "         video_topic 1.008755 Acceptable (1 < VIF < 5)                  LOW\n",
      "\n",
      "ğŸ“ˆ å¤šé‡å…±çº¿æ€§æ€»ç»“:\n",
      "  ä¸¥é‡å…±çº¿æ€§ (VIF â‰¥ 10): 0 ä¸ªç‰¹å¾\n",
      "  ä¸­åº¦å…±çº¿æ€§ (5 â‰¤ VIF < 10): 0 ä¸ªç‰¹å¾\n",
      "  å¯æ¥å—å…±çº¿æ€§ (VIF < 5): 14 ä¸ªç‰¹å¾\n",
      "âœ“ VIFå¯è§†åŒ–å·²ä¿å­˜ä¸º 'vif_analysis.png'\n",
      "âœ“ VIFåˆ†æç»“æœå·²ä¿å­˜åˆ° 'vif_analysis_results.xlsx'\n",
      "\n",
      "============================================================\n",
      "æ•°æ®é›†åˆ’åˆ†\n",
      "============================================================\n",
      "è®­ç»ƒé›†: (800, 14), æµ‹è¯•é›†: (200, 14)\n",
      "\n",
      "============================================================\n",
      "åˆå§‹åŒ–æ¨¡å‹\n",
      "============================================================\n",
      "âœ“ TabPFNå·²æ·»åŠ åˆ°æ¨¡å‹åˆ—è¡¨\n",
      "\n",
      "æ€»å…±æ¯”è¾ƒ 8 ä¸ªæ¨¡å‹: ['SVR', 'KNN', 'GBM', 'RandomForest', 'Ridge', 'XGBoost', 'LightGBM', 'TabPFN']\n",
      "\n",
      "============================================================\n",
      "è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ (10æŠ˜äº¤å‰éªŒè¯)\n",
      "============================================================\n",
      "\n",
      "--- è®­ç»ƒ SVR ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1309\n",
      "  æµ‹è¯•é›† RÂ²: 0.5987\n",
      "  æµ‹è¯•é›† MAE: 0.0831\n",
      "  æµ‹è¯•é›† MAPE: 56.58%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1300 Â± 0.0080\n",
      "  æœ€ä½³å‚æ•°: {'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "--- è®­ç»ƒ KNN ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1365\n",
      "  æµ‹è¯•é›† RÂ²: 0.5641\n",
      "  æµ‹è¯•é›† MAE: 0.1033\n",
      "  æµ‹è¯•é›† MAPE: 61.64%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1410 Â± 0.0080\n",
      "  æœ€ä½³å‚æ•°: {'n_neighbors': 20}\n",
      "\n",
      "--- è®­ç»ƒ GBM ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1189\n",
      "  æµ‹è¯•é›† RÂ²: 0.6693\n",
      "  æµ‹è¯•é›† MAE: 0.0714\n",
      "  æµ‹è¯•é›† MAPE: 41.14%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1275 Â± 0.0190\n",
      "  æœ€ä½³å‚æ•°: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "\n",
      "--- è®­ç»ƒ RandomForest ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1155\n",
      "  æµ‹è¯•é›† RÂ²: 0.6878\n",
      "  æµ‹è¯•é›† MAE: 0.0748\n",
      "  æµ‹è¯•é›† MAPE: 47.99%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1243 Â± 0.0123\n",
      "  æœ€ä½³å‚æ•°: {'max_depth': 20, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "\n",
      "--- è®­ç»ƒ Ridge ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1284\n",
      "  æµ‹è¯•é›† RÂ²: 0.6139\n",
      "  æµ‹è¯•é›† MAE: 0.0780\n",
      "  æµ‹è¯•é›† MAPE: 57.75%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1290 Â± 0.0088\n",
      "  æœ€ä½³å‚æ•°: {'alpha': 10}\n",
      "\n",
      "--- è®­ç»ƒ XGBoost ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1162\n",
      "  æµ‹è¯•é›† RÂ²: 0.6838\n",
      "  æµ‹è¯•é›† MAE: 0.0754\n",
      "  æµ‹è¯•é›† MAPE: 35.80%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1251 Â± 0.0160\n",
      "  æœ€ä½³å‚æ•°: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "--- è®­ç»ƒ LightGBM ---\n",
      "  æµ‹è¯•é›† RMSE: 0.1061\n",
      "  æµ‹è¯•é›† RÂ²: 0.7365\n",
      "  æµ‹è¯•é›† MAE: 0.0658\n",
      "  æµ‹è¯•é›† MAPE: 45.66%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1196 Â± 0.0137\n",
      "  æœ€ä½³å‚æ•°: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 30}\n",
      "\n",
      "--- è®­ç»ƒ TabPFN ---\n",
      "  æµ‹è¯•é›† RMSE: 0.0942\n",
      "  æµ‹è¯•é›† RÂ²: 0.7924\n",
      "  æµ‹è¯•é›† MAE: 0.0315\n",
      "  æµ‹è¯•é›† MAPE: 47.68%\n",
      "  äº¤å‰éªŒè¯ RMSE: 0.1017 Â± 0.0181\n",
      "\n",
      "============================================================\n",
      "ç½®ä¿¡åŒºé—´è®¡ç®— (95% CI)\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š æ¨¡å‹æ€§èƒ½æ€»ç»“ï¼ˆæŒ‰æµ‹è¯•é›†RMSEæ’åºï¼‰:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "æ¨¡å‹           æµ‹è¯•é›†RMSE (95% CI)               æµ‹è¯•é›†MAE (95% CI)                æµ‹è¯•é›†MAPE (95% CI)          æµ‹è¯•é›†RÂ² (95% CI)                \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "TabPFN       0.0942 [0.0644, 0.1171]        0.0315 [0.0201, 0.0437]        47.7% [8.3%, 102.6%]      0.7924 [0.6912, 0.8910]       \n",
      "LightGBM     0.1061 [0.0825, 0.1293]        0.0658 [0.0547, 0.0779]        45.7% [14.8%, 96.0%]      0.7365 [0.6266, 0.8296]       \n",
      "RandomForest 0.1155 [0.0891, 0.1382]        0.0748 [0.0624, 0.0870]        48.0% [16.4%, 92.9%]      0.6878 [0.5632, 0.7993]       \n",
      "XGBoost      0.1162 [0.0949, 0.1395]        0.0754 [0.0643, 0.0888]        35.8% [16.4%, 60.0%]      0.6838 [0.5506, 0.7836]       \n",
      "GBM          0.1189 [0.0910, 0.1440]        0.0714 [0.0589, 0.0846]        41.1% [15.4%, 80.4%]      0.6693 [0.5318, 0.7961]       \n",
      "Ridge        0.1284 [0.1008, 0.1533]        0.0780 [0.0640, 0.0920]        57.7% [17.8%, 122.1%]     0.6139 [0.4793, 0.7424]       \n",
      "SVR          0.1309 [0.1050, 0.1559]        0.0831 [0.0706, 0.0983]        56.6% [17.4%, 114.5%]     0.5987 [0.4497, 0.7234]       \n",
      "KNN          0.1365 [0.1176, 0.1559]        0.1033 [0.0914, 0.1171]        61.6% [25.4%, 118.3%]     0.5641 [0.4651, 0.6474]       \n",
      "\n",
      "============================================================\n",
      "ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ\n",
      "============================================================\n",
      "\n",
      "é…å¯¹tæ£€éªŒï¼šæ‰€æœ‰æ¨¡å‹ vs æœ€ä½³æ¨¡å‹ (TabPFN)\n",
      "====================================================================================================\n",
      "æ³¨æ„ï¼š\n",
      "1. å·®å¼‚ = å¯¹æ¯”æ¨¡å‹RMSE - æœ€ä½³æ¨¡å‹RMSE\n",
      "2. æ­£å€¼è¡¨ç¤ºæœ€ä½³æ¨¡å‹æ›´å¥½ï¼ˆRMSEæ›´å°ï¼‰\n",
      "3. tç»Ÿè®¡é‡æ£€éªŒå·®å¼‚æ˜¯å¦æ˜¾è‘—å¤§äº0\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs SVR:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  SVRå¹³å‡RMSE: 0.1300\n",
      "  å·®å¼‚(SVR - TabPFN): 0.0283\n",
      "  tç»Ÿè®¡é‡: 4.115\n",
      "  åŒä¾§på€¼: 0.0026\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0013\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs KNN:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  KNNå¹³å‡RMSE: 0.1410\n",
      "  å·®å¼‚(KNN - TabPFN): 0.0393\n",
      "  tç»Ÿè®¡é‡: 6.935\n",
      "  åŒä¾§på€¼: 0.0001\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0000\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs GBM:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  GBMå¹³å‡RMSE: 0.1275\n",
      "  å·®å¼‚(GBM - TabPFN): 0.0258\n",
      "  tç»Ÿè®¡é‡: 2.855\n",
      "  åŒä¾§på€¼: 0.0189\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0095\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs RandomForest:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  RandomForestå¹³å‡RMSE: 0.1243\n",
      "  å·®å¼‚(RandomForest - TabPFN): 0.0226\n",
      "  tç»Ÿè®¡é‡: 2.929\n",
      "  åŒä¾§på€¼: 0.0168\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0084\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs Ridge:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  Ridgeå¹³å‡RMSE: 0.1290\n",
      "  å·®å¼‚(Ridge - TabPFN): 0.0273\n",
      "  tç»Ÿè®¡é‡: 3.996\n",
      "  åŒä¾§på€¼: 0.0031\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0016\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs XGBoost:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  XGBoostå¹³å‡RMSE: 0.1251\n",
      "  å·®å¼‚(XGBoost - TabPFN): 0.0234\n",
      "  tç»Ÿè®¡é‡: 2.919\n",
      "  åŒä¾§på€¼: 0.0171\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0085\n",
      "\n",
      "ğŸ“Š éªŒè¯ TabPFN vs LightGBM:\n",
      "  TabPFNå¹³å‡RMSE: 0.1017\n",
      "  LightGBMå¹³å‡RMSE: 0.1196\n",
      "  å·®å¼‚(LightGBM - TabPFN): 0.0179\n",
      "  tç»Ÿè®¡é‡: 2.662\n",
      "  åŒä¾§på€¼: 0.0259\n",
      "  å•ä¾§på€¼(å·®å¼‚>0): 0.0130\n",
      "\n",
      "====================================================================================================\n",
      "é…å¯¹tæ£€éªŒæœ€ç»ˆç»“æœï¼ˆä½¿ç”¨å•ä¾§æ£€éªŒï¼‰:\n",
      "====================================================================================================\n",
      "æ¯”è¾ƒ                        å‡å€¼å·®          tç»Ÿè®¡é‡       på€¼(å•ä¾§)       Cohen's d  æ•ˆåº”é‡        æ˜¾è‘—æ€§       \n",
      "----------------------------------------------------------------------------------------------------\n",
      "TabPFN vs SVR                  0.0283     4.115      0.0013     2.023 å¤§          **        \n",
      "TabPFN vs KNN                  0.0393     6.935      0.0000     2.814 å¤§          ***       \n",
      "TabPFN vs GBM                  0.0258     2.855      0.0095     1.392 å¤§          **        \n",
      "TabPFN vs RandomForest         0.0226     2.929      0.0084     1.463 å¤§          **        \n",
      "TabPFN vs Ridge                0.0273     3.996      0.0016     1.922 å¤§          **        \n",
      "TabPFN vs XGBoost              0.0234     2.919      0.0085     1.371 å¤§          **        \n",
      "TabPFN vs LightGBM             0.0179     2.662      0.0130     1.117 å¤§          *         \n",
      "\n",
      "====================================================================================================\n",
      "ç»“æœè§£é‡Šè¯´æ˜:\n",
      "====================================================================================================\n",
      "1. å‡å€¼å·® = å¯¹æ¯”æ¨¡å‹RMSE - æœ€ä½³æ¨¡å‹RMSE\n",
      "2. æ­£å€¼è¡¨ç¤ºæœ€ä½³æ¨¡å‹çš„RMSEæ›´å°ï¼ˆæ€§èƒ½æ›´å¥½ï¼‰\n",
      "3. tç»Ÿè®¡é‡æ£€éªŒå‡å€¼å·®æ˜¯å¦æ˜¾è‘—å¤§äº0\n",
      "4. ä½¿ç”¨å•ä¾§på€¼ï¼Œæ£€éªŒæœ€ä½³æ¨¡å‹æ˜¯å¦æ˜¾è‘—ä¼˜äºå¯¹æ¯”æ¨¡å‹\n",
      "5. æ•ˆåº”é‡è§£é‡Šï¼š\n",
      "   - d â‰¥ 0.8: å¤§æ•ˆåº”\n",
      "   - 0.5 â‰¤ d < 0.8: ä¸­ç­‰æ•ˆåº”\n",
      "   - 0.2 â‰¤ d < 0.5: å°æ•ˆåº”\n",
      "   - d < 0.2: å¯å¿½ç•¥æ•ˆåº”\n",
      "====================================================================================================\n",
      "\n",
      "============================================================\n",
      "ç»“æœå¯è§†åŒ–ï¼ˆåŒ¹é…å‚è€ƒå›¾é£æ ¼ï¼‰\n",
      "============================================================\n",
      "âœ“ æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º 'model_comparison_with_ci.png'\n",
      "âœ“ SVR æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'SVR_predictions_scatter.png'\n",
      "âœ“ KNN æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'KNN_predictions_scatter.png'\n",
      "âœ“ GBM æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'GBM_predictions_scatter.png'\n",
      "âœ“ RandomForest æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'RandomForest_predictions_scatter.png'\n",
      "âœ“ Ridge æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'Ridge_predictions_scatter.png'\n",
      "âœ“ XGBoost æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'XGBoost_predictions_scatter.png'\n",
      "âœ“ LightGBM æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'LightGBM_predictions_scatter.png'\n",
      "âœ“ TabPFN æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º 'TabPFN_predictions_scatter.png'\n",
      "âœ“ æ‰€æœ‰æ¨¡å‹æ•£ç‚¹å›¾æ±‡æ€»å·²ä¿å­˜ä¸º 'all_models_predictions_scatter.png'\n",
      "âœ“ ç»Ÿè®¡æ˜¾è‘—æ€§å›¾å·²ä¿å­˜ä¸º 'statistical_significance_plot.png'\n",
      "\n",
      "============================================================\n",
      "ä¿å­˜æ‰€æœ‰ç»“æœ\n",
      "============================================================\n",
      "âœ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° 'statistical_analysis_full_results.xlsx'\n",
      "\n",
      "============================================================\n",
      "ç»Ÿè®¡åˆ†ææŠ¥å‘Š\n",
      "============================================================\n",
      "================================================================================\n",
      "                    æ¨¡å‹æ¯”è¾ƒç»Ÿè®¡æŠ¥å‘Š\n",
      "================================================================================\n",
      "æ•°æ®é›†: 1000 æ ·æœ¬, 15 ç‰¹å¾\n",
      "ç›®æ ‡å˜é‡: engagement_score\n",
      "æ¯”è¾ƒæ¨¡å‹æ•°: 8\n",
      "è¯„ä¼°æŒ‡æ ‡: RMSE, MAE, MAPE, RÂ²\n",
      "ç½®ä¿¡åŒºé—´: ä½¿ç”¨Bootstrapæ–¹æ³•è®¡ç®— (n=1000)\n",
      "\n",
      "ğŸ† æœ€ä½³æ¨¡å‹æ€§èƒ½æ€»ç»“:\n",
      "--------------------------------------------------------------------------------\n",
      "  æ¨¡å‹: TabPFN\n",
      "  æµ‹è¯•é›†RMSE: 0.0942 [0.0644, 0.1171]\n",
      "  æµ‹è¯•é›†MAE: 0.0315 [0.0201, 0.0437]\n",
      "  æµ‹è¯•é›†MAPE: 47.7% [8.3%, 102.6%]\n",
      "  æµ‹è¯•é›†RÂ²: 0.7924 [0.6912, 0.8910]\n",
      "  äº¤å‰éªŒè¯RMSE: 0.1017 [0.0880, 0.1153]\n",
      "\n",
      "ğŸ“Š å¤šé‡å…±çº¿æ€§åˆ†æ:\n",
      "  ä¸¥é‡å…±çº¿æ€§ç‰¹å¾ (VIF â‰¥ 10): 0\n",
      "  ä¸­åº¦å…±çº¿æ€§ç‰¹å¾ (5 â‰¤ VIF < 10): 0\n",
      "\n",
      "ğŸ“ˆ ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ:\n",
      "  é…å¯¹tæ£€éªŒæ˜¾è‘—æ•°é‡ (p < 0.05): 7/7\n",
      "  é…å¯¹tæ£€éªŒæ˜¾è‘—æ•°é‡ (p < 0.01): 6/7\n",
      "  é…å¯¹tæ£€éªŒæ˜¾è‘—æ•°é‡ (p < 0.001): 1/7\n",
      "  æ˜¾è‘—ä¼˜äºåŸºå‡†çš„æ¨¡å‹:\n",
      "    - TabPFN vs SVR ** (d=2.023)\n",
      "    - TabPFN vs KNN *** (d=2.814)\n",
      "    - TabPFN vs GBM ** (d=1.392)\n",
      "    - TabPFN vs RandomForest ** (d=1.463)\n",
      "    - TabPFN vs Ridge ** (d=1.922)\n",
      "    - TabPFN vs XGBoost ** (d=1.371)\n",
      "    - TabPFN vs LightGBM * (d=1.117)\n",
      "\n",
      "âœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° 'statistical_analysis_report.txt'\n",
      "\n",
      "============================================================\n",
      "âœ… ç»Ÿè®¡åˆ†æå®Œæˆï¼\n",
      "============================================================\n",
      "ç”Ÿæˆçš„æ–‡ä»¶:\n",
      "  1. statistical_analysis_full_results.xlsx - æ‰€æœ‰è¯¦ç»†ç»“æœ\n",
      "  2. vif_analysis_results.xlsx - å¤šé‡å…±çº¿æ€§åˆ†æ\n",
      "  3. model_comparison_with_ci.png - æ¨¡å‹å¯¹æ¯”å›¾ï¼ˆåŒ…å«RMSE/MAE/MAPEï¼‰\n",
      "  4. statistical_significance_plot.png - ç»Ÿè®¡æ˜¾è‘—æ€§å›¾\n",
      "  5. statistical_analysis_report.txt - åˆ†ææŠ¥å‘Š\n",
      "  6. all_models_predictions_scatter.png - æ‰€æœ‰æ¨¡å‹æ•£ç‚¹å›¾æ±‡æ€»\n",
      "  7. SVR_predictions_scatter.png - SVRæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. KNN_predictions_scatter.png - KNNæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. GBM_predictions_scatter.png - GBMæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. RandomForest_predictions_scatter.png - RandomForestæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. Ridge_predictions_scatter.png - Ridgeæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. XGBoost_predictions_scatter.png - XGBoostæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. LightGBM_predictions_scatter.png - LightGBMæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  7. TabPFN_predictions_scatter.png - TabPFNæ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\n",
      "  16. vif_analysis.png - VIFå¯è§†åŒ–å›¾\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from tabpfn import TabPFNRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾\n",
    "plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·\n",
    "# åŒ¹é…å‚è€ƒå›¾çš„æ ·å¼é…ç½®\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linestyle'] = '-'\n",
    "\n",
    "# ============ 1. åŠ è½½æ•°æ® ============\n",
    "print(\"=\"*60)\n",
    "print(\"åŠ è½½æ•°æ®\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶\n",
    "LOCAL_MODEL_PATH = \"tabpfn-v2-regressor.ckpt\"\n",
    "tabpfn_available = os.path.exists(LOCAL_MODEL_PATH)\n",
    "\n",
    "# åŠ è½½æ•°æ®ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰\n",
    "data_files = [\"dataset/tabpfn_dataset_1000.xlsx\"]\n",
    "df = None\n",
    "for file in data_files:\n",
    "    try:\n",
    "        if file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file)\n",
    "        else:\n",
    "            df = pd.read_csv(file)\n",
    "        print(f\"âœ“ æˆåŠŸåŠ è½½æ•°æ®: {file}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "if df is None:\n",
    "    print(\"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶\")\n",
    "    print(\"è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€å­˜åœ¨:\", data_files)\n",
    "    exit()\n",
    "\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"åˆ—å: {list(df.columns)}\")\n",
    "\n",
    "# ============ 2. å¤šé‡å…±çº¿æ€§æ£€éªŒ (VIFåˆ†æ) ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å¤šé‡å…±çº¿æ€§æ£€éªŒ (VIFåˆ†æ)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_vif(X_data, threshold=5):\n",
    "    \"\"\"è®¡ç®—VIFå€¼å¹¶è¯†åˆ«é«˜åº¦å…±çº¿æ€§ç‰¹å¾\"\"\"\n",
    "    print(\"è®¡ç®—æ–¹å·®è†¨èƒ€å› å­(VIF)...\")\n",
    "    \n",
    "    # ç¡®ä¿æ˜¯DataFrameæ ¼å¼\n",
    "    if not isinstance(X_data, pd.DataFrame):\n",
    "        X_data = pd.DataFrame(X_data)\n",
    "    \n",
    "    # æ·»åŠ å¸¸æ•°é¡¹\n",
    "    X_with_const = add_constant(X_data)\n",
    "    \n",
    "    # è®¡ç®—VIF\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_with_const.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i) \n",
    "                      for i in range(X_with_const.shape[1])]\n",
    "    \n",
    "    # ç§»é™¤å¸¸æ•°é¡¹\n",
    "    vif_data = vif_data[vif_data[\"Feature\"] != \"const\"]\n",
    "    \n",
    "    # åˆ†ç±»\n",
    "    vif_data[\"Collinearity_Level\"] = vif_data[\"VIF\"].apply(\n",
    "        lambda x: \"Severe (VIF â‰¥ 10)\" if x >= 10 else \n",
    "                  \"Moderate (5 â‰¤ VIF < 10)\" if x >= 5 else \n",
    "                  \"Acceptable (1 < VIF < 5)\" if x > 1 else \"Low (VIF â‰¤ 1)\"\n",
    "    )\n",
    "    \n",
    "    vif_data[\"Collinearity_Concern\"] = vif_data[\"VIF\"].apply(\n",
    "        lambda x: \"HIGH\" if x >= 10 else \"MODERATE\" if x >= 5 else \"LOW\"\n",
    "    )\n",
    "    \n",
    "    return vif_data.sort_values(\"VIF\", ascending=False)\n",
    "\n",
    "# å‡†å¤‡æ•°æ®\n",
    "target_col = 'engagement_score'\n",
    "if target_col not in df.columns:\n",
    "    print(f\"è­¦å‘Šï¼šæ‰¾ä¸åˆ° '{target_col}' åˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºç›®æ ‡å˜é‡\")\n",
    "    target_col = df.columns[0]\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# åªé€‰æ‹©æ•°å€¼å‹ç‰¹å¾è¿›è¡ŒVIFåˆ†æ\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(numeric_cols) > 0:\n",
    "    X_numeric = X[numeric_cols]\n",
    "    vif_results = calculate_vif(X_numeric)\n",
    "    \n",
    "    print(\"\\nğŸ“Š VIFåˆ†æç»“æœ:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(vif_results.to_string(index=False))\n",
    "    \n",
    "    # ç»Ÿè®¡æ€»ç»“\n",
    "    high_vif = vif_results[vif_results[\"VIF\"] >= 10]\n",
    "    moderate_vif = vif_results[(vif_results[\"VIF\"] >= 5) & (vif_results[\"VIF\"] < 10)]\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ å¤šé‡å…±çº¿æ€§æ€»ç»“:\")\n",
    "    print(f\"  ä¸¥é‡å…±çº¿æ€§ (VIF â‰¥ 10): {len(high_vif)} ä¸ªç‰¹å¾\")\n",
    "    print(f\"  ä¸­åº¦å…±çº¿æ€§ (5 â‰¤ VIF < 10): {len(moderate_vif)} ä¸ªç‰¹å¾\")\n",
    "    print(f\"  å¯æ¥å—å…±çº¿æ€§ (VIF < 5): {len(vif_results) - len(high_vif) - len(moderate_vif)} ä¸ªç‰¹å¾\")\n",
    "    \n",
    "    if len(high_vif) > 0:\n",
    "        print(f\"\\nâš ï¸  å»ºè®®å¤„ç†ä»¥ä¸‹é«˜VIFç‰¹å¾:\")\n",
    "        for _, row in high_vif.iterrows():\n",
    "            print(f\"  {row['Feature']}: VIF = {row['VIF']:.2f}\")\n",
    "    \n",
    "    # å¯è§†åŒ–VIFç»“æœ\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['red' if v >= 10 else 'orange' if v >= 5 else 'green' for v in vif_results[\"VIF\"]]\n",
    "    bars = plt.barh(range(len(vif_results)), vif_results[\"VIF\"], color=colors)\n",
    "    plt.axvline(x=5, color='orange', linestyle='--', alpha=0.7, label='VIF = 5 (é˜ˆå€¼)')\n",
    "    plt.axvline(x=10, color='red', linestyle='--', alpha=0.7, label='VIF = 10 (ä¸¥é‡)')\n",
    "    plt.xlabel('Variance Inflation Factor (VIF)')\n",
    "    plt.title('å¤šé‡å…±çº¿æ€§æ£€éªŒ (VIFåˆ†æ)')\n",
    "    plt.yticks(range(len(vif_results)), vif_results[\"Feature\"])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('vif_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"âœ“ VIFå¯è§†åŒ–å·²ä¿å­˜ä¸º 'vif_analysis.png'\")\n",
    "    \n",
    "    # ä¿å­˜VIFç»“æœ\n",
    "    vif_results.to_excel('vif_analysis_results.xlsx', index=False)\n",
    "    print(\"âœ“ VIFåˆ†æç»“æœå·²ä¿å­˜åˆ° 'vif_analysis_results.xlsx'\")\n",
    "else:\n",
    "    print(\"âš ï¸  æ²¡æœ‰æ•°å€¼å‹ç‰¹å¾ï¼Œè·³è¿‡VIFåˆ†æ\")\n",
    "\n",
    "# ============ 3. åˆ’åˆ†æ•°æ®é›† ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ•°æ®é›†åˆ’åˆ†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åˆ’åˆ†æ•°æ®é›†ï¼ˆ8:2ï¼Œä¿ç•™20%ä½œä¸ºæœ€ç»ˆæµ‹è¯•é›†ï¼‰\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}\")\n",
    "\n",
    "# ============ 4. æ•°æ®æ ‡å‡†åŒ– ============\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ============ 5. åˆå§‹åŒ–æ¨¡å‹ ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"åˆå§‹åŒ–æ¨¡å‹\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# é¦–å…ˆå®šä¹‰TabPFNåŒ…è£…å™¨ç±»\n",
    "class TabPFNWrapper:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        try:\n",
    "            from tabpfn import TabPFNRegressor\n",
    "            if tabpfn_available:\n",
    "                self.model = TabPFNRegressor(device='cpu', model_path=LOCAL_MODEL_PATH)\n",
    "                self.model.fit(X.values if hasattr(X, 'values') else X, \n",
    "                              y.values if hasattr(y, 'values') else y)\n",
    "                self.is_fitted = True\n",
    "            else:\n",
    "                raise ImportError(\"TabPFNæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°\")\n",
    "        except ImportError as e:\n",
    "            print(f\"TabPFNä¸å¯ç”¨: {e}\")\n",
    "            raise\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None or not self.is_fitted:\n",
    "            raise ValueError(\"æ¨¡å‹æœªè®­ç»ƒ\")\n",
    "        return self.model.predict(X.values if hasattr(X, 'values') else X)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        return self\n",
    "\n",
    "# å®šä¹‰æ‰€æœ‰æ¨¡å‹\n",
    "models = {\n",
    "    'SVR': (SVR(), {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}),\n",
    "    'KNN': (KNeighborsRegressor(), {'n_neighbors': [3, 5, 7, 9, 11, 15, 20, 40]}),\n",
    "    'GBM': (GradientBoostingRegressor(random_state=42), {\n",
    "        'n_estimators': [50, 100, 200, 300], \n",
    "        'learning_rate': [0.01, 0.1, 0.5, 1, 5], \n",
    "        'max_depth': [5, 10, 15, 20, 40, 50]\n",
    "    }),\n",
    "    'RandomForest': (RandomForestRegressor(random_state=42), {\n",
    "        'n_estimators': [50, 100, 200, 300], \n",
    "        'max_depth': [5, 10, 15, 20], \n",
    "        'min_samples_split': [4, 8, 12, 16, 20]\n",
    "    }),\n",
    "    'Ridge': (Ridge(random_state=42), {'alpha': [0.1, 1, 10, 100]}),\n",
    "    'XGBoost': (xgb.XGBRegressor(random_state=42, verbosity=0), {\n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'learning_rate': [0.01, 0.05, 0.1], \n",
    "        'max_depth': [3, 6, 10], \n",
    "        'subsample': [0.8, 1.0]\n",
    "    }),\n",
    "    'LightGBM': (lgb.LGBMRegressor(random_state=42, verbose=-1), {\n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'learning_rate': [0.01, 0.05, 0.1], \n",
    "        'max_depth': [3, 6, 10], \n",
    "        'num_leaves': [5, 10, 15, 20, 30]\n",
    "    })\n",
    "}\n",
    "\n",
    "# æ·»åŠ TabPFNï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "if tabpfn_available:\n",
    "    try:\n",
    "        models['TabPFN'] = (TabPFNWrapper(), {})\n",
    "        print(\"âœ“ TabPFNå·²æ·»åŠ åˆ°æ¨¡å‹åˆ—è¡¨\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  TabPFNåˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸  TabPFNæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·³è¿‡TabPFN\")\n",
    "\n",
    "print(f\"\\næ€»å…±æ¯”è¾ƒ {len(models)} ä¸ªæ¨¡å‹: {list(models.keys())}\")\n",
    "\n",
    "# ============ 6. è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ (10æŠ˜äº¤å‰éªŒè¯)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = {}\n",
    "model_predictions = {}\n",
    "\n",
    "for name, (model, param_grid) in models.items():\n",
    "    print(f\"\\n--- è®­ç»ƒ {name} ---\")\n",
    "    \n",
    "    try:\n",
    "        # åŒºåˆ†TabPFNå’Œå…¶ä»–æ¨¡å‹\n",
    "        is_tabpfn = name == 'TabPFN'\n",
    "        \n",
    "        if is_tabpfn:\n",
    "            # TabPFNï¼šä½¿ç”¨åŸå§‹æ•°æ®ï¼Œæ— ç½‘æ ¼æœç´¢\n",
    "            best_model = model\n",
    "            best_model.fit(X_train, y_train)\n",
    "            best_params = \"TabPFN (é¢„è®­ç»ƒæ¨¡å‹)\"\n",
    "            X_eval_train = X_train\n",
    "            X_eval_test = X_test\n",
    "            \n",
    "            # å¯¹äºTabPFNï¼Œæˆ‘ä»¬éœ€è¦ç‰¹æ®Šçš„äº¤å‰éªŒè¯\n",
    "            cv_rmse_scores = []\n",
    "            for i in range(10):\n",
    "                # ä½¿ç”¨ä¸åŒçš„éšæœºç§å­åˆ›å»ºè®­ç»ƒ/éªŒè¯åˆ†å‰²\n",
    "                X_train_cv, X_val_cv, y_train_cv, y_val_cv = train_test_split(\n",
    "                    X_train, y_train, test_size=0.1, random_state=i\n",
    "                )\n",
    "                \n",
    "                # è®­ç»ƒTabPFN\n",
    "                temp_model = TabPFNWrapper()\n",
    "                temp_model.fit(X_train_cv, y_train_cv)\n",
    "                \n",
    "                # é¢„æµ‹å¹¶è®¡ç®—RMSE\n",
    "                y_pred_cv = temp_model.predict(X_val_cv)\n",
    "                rmse_cv = np.sqrt(np.mean((y_val_cv - y_pred_cv) ** 2))\n",
    "                cv_rmse_scores.append(rmse_cv)\n",
    "            \n",
    "            cv_rmse_scores = np.array(cv_rmse_scores)\n",
    "            \n",
    "        else:\n",
    "            # å…¶ä»–æ¨¡å‹ï¼šç½‘æ ¼æœç´¢ + æ ‡å‡†åŒ–æ•°æ®\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=10,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            X_eval_train = X_train_scaled\n",
    "            X_eval_test = X_test_scaled\n",
    "            \n",
    "            # äº¤å‰éªŒè¯åˆ†æ•°\n",
    "            cv_scores = cross_val_score(\n",
    "                best_model, X_eval_train, y_train,\n",
    "                cv=10, scoring='neg_mean_squared_error', n_jobs=-1\n",
    "            )\n",
    "            cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "        \n",
    "        # æµ‹è¯•é›†è¯„ä¼°\n",
    "        y_pred = best_model.predict(X_eval_test)\n",
    "        \n",
    "        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡\n",
    "        mse = np.mean((y_test - y_pred) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(y_test - y_pred))\n",
    "        r2 = 1 - np.sum((y_test - y_pred) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "        \n",
    "        # ====== æ–°å¢ï¼šè®¡ç®—MAPE ======\n",
    "        # é¿å…é™¤é›¶é”™è¯¯\n",
    "        mask = y_test != 0  # ç­›é€‰å‡ºy_testéé›¶çš„æ ·æœ¬\n",
    "        if np.any(mask):\n",
    "            # åªè®¡ç®—éé›¶æ ·æœ¬çš„MAPE\n",
    "            mape = np.mean(np.abs((y_test[mask] - y_pred[mask]) / y_test[mask])) * 100\n",
    "        else:\n",
    "            # è‹¥æ‰€æœ‰y_testéƒ½æ˜¯0ï¼ŒMAPEæ— æ„ä¹‰ï¼Œè®¾ä¸º0æˆ–NaN\n",
    "            mape = np.nan  # æˆ– 0.0ï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©\n",
    "        \n",
    "        # ä¿å­˜ç»“æœ\n",
    "        results[name] = {\n",
    "            'model': best_model,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mae': mae,\n",
    "            'mape': mape,  # æ–°å¢\n",
    "            'cv_rmse_scores': cv_rmse_scores,\n",
    "            'best_params': best_params,\n",
    "            'y_pred': y_pred,\n",
    "            'y_test': y_test.values\n",
    "        }\n",
    "        \n",
    "        model_predictions[name] = y_pred\n",
    "        \n",
    "        print(f\"  æµ‹è¯•é›† RMSE: {rmse:.4f}\")\n",
    "        print(f\"  æµ‹è¯•é›† RÂ²: {r2:.4f}\")\n",
    "        print(f\"  æµ‹è¯•é›† MAE: {mae:.4f}\")\n",
    "        print(f\"  æµ‹è¯•é›† MAPE: {mape:.2f}%\")  # æ–°å¢\n",
    "        print(f\"  äº¤å‰éªŒè¯ RMSE: {np.mean(cv_rmse_scores):.4f} Â± {np.std(cv_rmse_scores):.4f}\")\n",
    "        \n",
    "        if not is_tabpfn:\n",
    "            print(f\"  æœ€ä½³å‚æ•°: {best_params}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— è®­ç»ƒå¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============ 7. ç½®ä¿¡åŒºé—´è®¡ç®— ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç½®ä¿¡åŒºé—´è®¡ç®— (95% CI)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"è®¡ç®—ç½®ä¿¡åŒºé—´\"\"\"\n",
    "    n = len(data)\n",
    "    if n < 2:\n",
    "        return np.mean(data), np.mean(data), np.mean(data)\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # æ ‡å‡†è¯¯\n",
    "    t_val = stats.t.ppf((1 + confidence) / 2, n - 1)\n",
    "    ci = t_val * sem\n",
    "    \n",
    "    return mean, mean - ci, mean + ci\n",
    "\n",
    "# ä¸ºæ¯ä¸ªæ¨¡å‹è®¡ç®—ç½®ä¿¡åŒºé—´\n",
    "performance_summary = []\n",
    "\n",
    "for name, res in results.items():\n",
    "    # è®¡ç®—äº¤å‰éªŒè¯RMSEçš„ç½®ä¿¡åŒºé—´\n",
    "    cv_mean, ci_lower, ci_upper = calculate_confidence_interval(res['cv_rmse_scores'])\n",
    "    \n",
    "    # è®¡ç®—æµ‹è¯•é›†æŒ‡æ ‡çš„ç½®ä¿¡åŒºé—´ï¼ˆä½¿ç”¨Bootstrapï¼‰\n",
    "    n_bootstrap = 1000\n",
    "    bootstrap_rmse = []\n",
    "    bootstrap_r2 = []\n",
    "    bootstrap_mae = []\n",
    "    bootstrap_mape = []  # æ–°å¢\n",
    "    \n",
    "    n_samples = len(y_test)\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Bootstrapé‡é‡‡æ ·\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        y_test_boot = y_test.values[indices]\n",
    "        y_pred_boot = res['y_pred'][indices]\n",
    "        \n",
    "        # é¿å…é™¤é›¶ï¼ˆé’ˆå¯¹MAPEè®¡ç®—ï¼‰\n",
    "        y_test_boot_nonzero = y_test_boot.copy()\n",
    "        y_test_boot_nonzero[y_test_boot_nonzero == 0] = 1e-10\n",
    "        \n",
    "        # è®¡ç®—æŒ‡æ ‡\n",
    "        bootstrap_rmse.append(np.sqrt(np.mean((y_test_boot - y_pred_boot) ** 2)))\n",
    "        bootstrap_r2.append(1 - np.sum((y_test_boot - y_pred_boot) ** 2) / \n",
    "                           np.sum((y_test_boot - np.mean(y_test_boot)) ** 2))\n",
    "        bootstrap_mae.append(np.mean(np.abs(y_test_boot - y_pred_boot)))\n",
    "        bootstrap_mape.append(np.mean(np.abs((y_test_boot - y_pred_boot) / y_test_boot_nonzero)) * 100)  # æ–°å¢\n",
    "    \n",
    "    # Bootstrapç½®ä¿¡åŒºé—´\n",
    "    rmse_ci_lower, rmse_ci_upper = np.percentile(bootstrap_rmse, [2.5, 97.5])\n",
    "    r2_ci_lower, r2_ci_upper = np.percentile(bootstrap_r2, [2.5, 97.5])\n",
    "    mae_ci_lower, mae_ci_upper = np.percentile(bootstrap_mae, [2.5, 97.5])\n",
    "    mape_ci_lower, mape_ci_upper = np.percentile(bootstrap_mape, [2.5, 97.5])  # æ–°å¢\n",
    "    \n",
    "    performance_summary.append({\n",
    "        'Model': name,\n",
    "        # æµ‹è¯•é›†æŒ‡æ ‡ + Bootstrap CI\n",
    "        'Test_RMSE': f\"{res['rmse']:.4f} [{rmse_ci_lower:.4f}, {rmse_ci_upper:.4f}]\",\n",
    "        'Test_MAE': f\"{res['mae']:.4f} [{mae_ci_lower:.4f}, {mae_ci_upper:.4f}]\",\n",
    "        'Test_MAPE': f\"{res['mape']:.1f}% [{mape_ci_lower:.1f}%, {mape_ci_upper:.1f}%]\",  # æ–°å¢\n",
    "        'Test_R2': f\"{res['r2']:.4f} [{r2_ci_lower:.4f}, {r2_ci_upper:.4f}]\",\n",
    "        # äº¤å‰éªŒè¯æŒ‡æ ‡ + ç†è®ºCI\n",
    "        'CV_RMSE_mean': cv_mean,\n",
    "        'CV_RMSE_std': np.std(res['cv_rmse_scores']),\n",
    "        'CV_RMSE_CI_lower': ci_lower,\n",
    "        'CV_RMSE_CI_upper': ci_upper,\n",
    "        'CV_RMSE_CI_width': ci_upper - ci_lower,\n",
    "        # åŸå§‹æ•°å€¼ï¼ˆç”¨äºæ’åºï¼‰\n",
    "        'rmse_value': res['rmse'],\n",
    "        'mae_value': res['mae'],\n",
    "        'mape_value': res['mape'],  # æ–°å¢\n",
    "        'r2_value': res['r2']\n",
    "    })\n",
    "\n",
    "# åˆ›å»ºDataFrameå¹¶æ’åº\n",
    "summary_df = pd.DataFrame(performance_summary)\n",
    "summary_df_sorted = summary_df.sort_values('rmse_value')\n",
    "\n",
    "print(\"\\nğŸ“Š æ¨¡å‹æ€§èƒ½æ€»ç»“ï¼ˆæŒ‰æµ‹è¯•é›†RMSEæ’åºï¼‰:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'æ¨¡å‹':<12} {'æµ‹è¯•é›†RMSE (95% CI)':<30} {'æµ‹è¯•é›†MAE (95% CI)':<30} {'æµ‹è¯•é›†MAPE (95% CI)':<25} {'æµ‹è¯•é›†RÂ² (95% CI)':<30}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for _, row in summary_df_sorted.iterrows():\n",
    "    print(f\"{row['Model']:<12} {row['Test_RMSE']:<30} {row['Test_MAE']:<30} \"\n",
    "          f\"{row['Test_MAPE']:<25} {row['Test_R2']:<30}\")\n",
    "\n",
    "# ============ 8. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(results) >= 2:\n",
    "    # è·å–æ‰€æœ‰æ¨¡å‹çš„äº¤å‰éªŒè¯åˆ†æ•°\n",
    "    model_names = list(results.keys())\n",
    "    cv_scores_dict = {name: results[name]['cv_rmse_scores'] for name in model_names}\n",
    "    \n",
    "    # è¯†åˆ«æœ€ä½³æ¨¡å‹\n",
    "    best_model_name = summary_df_sorted.iloc[0]['Model']\n",
    "    print(f\"\\né…å¯¹tæ£€éªŒï¼šæ‰€æœ‰æ¨¡å‹ vs æœ€ä½³æ¨¡å‹ ({best_model_name})\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"æ³¨æ„ï¼š\")\n",
    "    print(\"1. å·®å¼‚ = å¯¹æ¯”æ¨¡å‹RMSE - æœ€ä½³æ¨¡å‹RMSE\")\n",
    "    print(\"2. æ­£å€¼è¡¨ç¤ºæœ€ä½³æ¨¡å‹æ›´å¥½ï¼ˆRMSEæ›´å°ï¼‰\")\n",
    "    print(\"3. tç»Ÿè®¡é‡æ£€éªŒå·®å¼‚æ˜¯å¦æ˜¾è‘—å¤§äº0\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    t_test_results = []\n",
    "    for model_name in model_names:\n",
    "        if model_name != best_model_name:\n",
    "            # è·å–åˆ†æ•°\n",
    "            scores_best = cv_scores_dict[best_model_name]\n",
    "            scores_other = cv_scores_dict[model_name]\n",
    "            \n",
    "            # ç¡®ä¿é•¿åº¦ç›¸åŒ\n",
    "            min_len = min(len(scores_best), len(scores_other))\n",
    "            if min_len >= 2:\n",
    "                scores_best_adj = scores_best[:min_len]\n",
    "                scores_other_adj = scores_other[:min_len]\n",
    "                \n",
    "                # ========== å…³é”®ä¿®æ­£ï¼šæ­£ç¡®çš„æ¯”è¾ƒæ–¹å‘ ==========\n",
    "                # è®¡ç®—å·®å¼‚ï¼šå¯¹æ¯”æ¨¡å‹ - æœ€ä½³æ¨¡å‹\n",
    "                # å¦‚æœæœ€ä½³æ¨¡å‹æ›´å¥½ï¼ˆRMSEæ›´å°ï¼‰ï¼Œå·®å¼‚åº”è¯¥ä¸ºæ­£æ•°\n",
    "                differences = scores_other_adj - scores_best_adj\n",
    "                \n",
    "                # é…å¯¹tæ£€éªŒï¼šæ£€éªŒå·®å¼‚æ˜¯å¦æ˜¾è‘—å¤§äº0ï¼ˆå•ä¾§æ£€éªŒï¼‰\n",
    "                # ä½¿ç”¨stats.t.cdfè¿›è¡Œå•ä¾§æ£€éªŒ\n",
    "                t_stat, p_value_two_sided = stats.ttest_rel(differences, 0)\n",
    "                \n",
    "                # è½¬æ¢ä¸ºå•ä¾§på€¼ï¼ˆæ£€éªŒå·®å¼‚æ˜¯å¦>0ï¼‰\n",
    "                if t_stat > 0:\n",
    "                    # tå€¼ä¸ºæ­£ï¼Œæ£€éªŒå·®å¼‚æ˜¯å¦æ˜¾è‘—å¤§äº0\n",
    "                    p_value_one_sided = p_value_two_sided / 2\n",
    "                else:\n",
    "                    # tå€¼ä¸ºè´Ÿï¼Œå·®å¼‚å°äº0ï¼Œå¯¹å½“å‰å‡è®¾ä¸åˆ©\n",
    "                    p_value_one_sided = 1 - p_value_two_sided / 2\n",
    "                \n",
    "                # å‡å€¼å·®ï¼ˆå¯¹æ¯”æ¨¡å‹ - æœ€ä½³æ¨¡å‹ï¼‰\n",
    "                mean_diff = np.mean(differences)\n",
    "                \n",
    "                # æ•ˆåº”é‡\n",
    "                pooled_std = np.sqrt((np.var(scores_best_adj) + np.var(scores_other_adj)) / 2)\n",
    "                cohens_d = mean_diff / pooled_std if pooled_std != 0 else 0\n",
    "                \n",
    "                # ========== éªŒè¯æ‰“å° ==========\n",
    "                print(f\"\\nğŸ“Š éªŒè¯ {best_model_name} vs {model_name}:\")\n",
    "                print(f\"  {best_model_name}å¹³å‡RMSE: {np.mean(scores_best_adj):.4f}\")\n",
    "                print(f\"  {model_name}å¹³å‡RMSE: {np.mean(scores_other_adj):.4f}\")\n",
    "                print(f\"  å·®å¼‚({model_name} - {best_model_name}): {mean_diff:.4f}\")\n",
    "                print(f\"  tç»Ÿè®¡é‡: {t_stat:.3f}\")\n",
    "                print(f\"  åŒä¾§på€¼: {p_value_two_sided:.4f}\")\n",
    "                print(f\"  å•ä¾§på€¼(å·®å¼‚>0): {p_value_one_sided:.4f}\")\n",
    "                \n",
    "                # æ•ˆåº”é‡è§£é‡Š\n",
    "                if abs(cohens_d) >= 0.8:\n",
    "                    effect_magnitude = \"å¤§\"\n",
    "                elif abs(cohens_d) >= 0.5:\n",
    "                    effect_magnitude = \"ä¸­\"\n",
    "                elif abs(cohens_d) >= 0.2:\n",
    "                    effect_magnitude = \"å°\"\n",
    "                else:\n",
    "                    effect_magnitude = \"å¯å¿½ç•¥\"\n",
    "                \n",
    "                # åˆ¤æ–­æ˜¾è‘—æ€§ï¼ˆå•ä¾§æ£€éªŒï¼‰\n",
    "                sig_005 = p_value_one_sided < 0.05 and mean_diff > 0\n",
    "                sig_001 = p_value_one_sided < 0.01 and mean_diff > 0\n",
    "                sig_0001 = p_value_one_sided < 0.001 and mean_diff > 0\n",
    "                \n",
    "                # å†³å®šä½¿ç”¨å“ªä¸ªtå€¼ï¼šå¦‚æœmean_diffä¸ºæ­£ï¼Œä½†t_statä¸ºè´Ÿï¼Œå–ç»å¯¹å€¼\n",
    "                # è¿™é€šå¸¸å‘ç”Ÿåœ¨è®¡ç®—é¡ºåºé—®é¢˜æ—¶\n",
    "                report_t_stat = t_stat\n",
    "                if mean_diff > 0 and t_stat < 0:\n",
    "                    print(f\"  âš ï¸  æ³¨æ„ï¼šå‡å€¼å·®ä¸ºæ­£ä½†tå€¼ä¸ºè´Ÿï¼Œä½¿ç”¨|t|å€¼\")\n",
    "                    report_t_stat = abs(t_stat)\n",
    "                \n",
    "                t_test_results.append({\n",
    "                    'Comparison': f\"{best_model_name} vs {model_name}\",\n",
    "                    'Best_Mean_RMSE': np.mean(scores_best_adj),\n",
    "                    'Other_Mean_RMSE': np.mean(scores_other_adj),\n",
    "                    'Mean_Difference': mean_diff,  # å¯¹æ¯”æ¨¡å‹ - æœ€ä½³æ¨¡å‹\n",
    "                    't_statistic': report_t_stat,  # ä¿®æ­£åçš„tå€¼\n",
    "                    'p_value_two_sided': p_value_two_sided,\n",
    "                    'p_value_one_sided': p_value_one_sided,\n",
    "                    'cohens_d': cohens_d,\n",
    "                    'effect_magnitude': effect_magnitude,\n",
    "                    'significant_0.05': sig_005,\n",
    "                    'significant_0.01': sig_001,\n",
    "                    'significant_0.001': sig_0001,\n",
    "                    'sig_stars': \"***\" if sig_0001 else \"**\" if sig_001 else \"*\" if sig_005 else \"\"\n",
    "                })\n",
    "    \n",
    "    # åˆ›å»ºtæ£€éªŒç»“æœDataFrame\n",
    "    if t_test_results:\n",
    "        t_test_df = pd.DataFrame(t_test_results)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*100)\n",
    "        print(f\"é…å¯¹tæ£€éªŒæœ€ç»ˆç»“æœï¼ˆä½¿ç”¨å•ä¾§æ£€éªŒï¼‰:\")\n",
    "        print(\"=\"*100)\n",
    "        print(f\"{'æ¯”è¾ƒ':<25} {'å‡å€¼å·®':<12} {'tç»Ÿè®¡é‡':<10} {'på€¼(å•ä¾§)':<12} {'Cohen\\'s d':<10} {'æ•ˆåº”é‡':<10} {'æ˜¾è‘—æ€§':<10}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for _, row in t_test_df.iterrows():\n",
    "            print(f\"{row['Comparison']:<25} {row['Mean_Difference']:>11.4f} {row['t_statistic']:>9.3f} \"\n",
    "                  f\"{row['p_value_one_sided']:>11.4f} {row['cohens_d']:>9.3f} \"\n",
    "                  f\"{row['effect_magnitude']:<10} {row['sig_stars']:<10}\")\n",
    "        \n",
    "        # æ·»åŠ è§£é‡Šè¯´æ˜\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"ç»“æœè§£é‡Šè¯´æ˜:\")\n",
    "        print(\"=\"*100)\n",
    "        print(\"1. å‡å€¼å·® = å¯¹æ¯”æ¨¡å‹RMSE - æœ€ä½³æ¨¡å‹RMSE\")\n",
    "        print(\"2. æ­£å€¼è¡¨ç¤ºæœ€ä½³æ¨¡å‹çš„RMSEæ›´å°ï¼ˆæ€§èƒ½æ›´å¥½ï¼‰\")\n",
    "        print(\"3. tç»Ÿè®¡é‡æ£€éªŒå‡å€¼å·®æ˜¯å¦æ˜¾è‘—å¤§äº0\")\n",
    "        print(\"4. ä½¿ç”¨å•ä¾§på€¼ï¼Œæ£€éªŒæœ€ä½³æ¨¡å‹æ˜¯å¦æ˜¾è‘—ä¼˜äºå¯¹æ¯”æ¨¡å‹\")\n",
    "        print(\"5. æ•ˆåº”é‡è§£é‡Šï¼š\")\n",
    "        print(\"   - d â‰¥ 0.8: å¤§æ•ˆåº”\")\n",
    "        print(\"   - 0.5 â‰¤ d < 0.8: ä¸­ç­‰æ•ˆåº”\")\n",
    "        print(\"   - 0.2 â‰¤ d < 0.5: å°æ•ˆåº”\")\n",
    "        print(\"   - d < 0.2: å¯å¿½ç•¥æ•ˆåº”\")\n",
    "        print(\"=\"*100)\n",
    "\n",
    "# ============ 9. å¯è§†åŒ–ç»“æœï¼ˆå®Œå…¨åŒ¹é…å‚è€ƒå›¾é£æ ¼ï¼‰ ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç»“æœå¯è§†åŒ–ï¼ˆåŒ¹é…å‚è€ƒå›¾é£æ ¼ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 9.1 æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# å­å›¾1ï¼šæµ‹è¯•é›†RMSEå¯¹æ¯”\n",
    "plt.subplot(2, 2, 1)\n",
    "model_names_plot = summary_df_sorted['Model'].tolist()\n",
    "rmse_values = summary_df_sorted['rmse_value'].tolist()\n",
    "\n",
    "# æå–ç½®ä¿¡åŒºé—´\n",
    "rmse_ci_lower = []\n",
    "rmse_ci_upper = []\n",
    "for rmse_str in summary_df_sorted['Test_RMSE']:\n",
    "    ci_parts = rmse_str.split('[')[1].split(']')[0].split(', ')\n",
    "    rmse_ci_lower.append(float(ci_parts[0]))\n",
    "    rmse_ci_upper.append(float(ci_parts[1]))\n",
    "\n",
    "ci_errors = [rmse_values[i] - rmse_ci_lower[i] for i in range(len(rmse_values))]\n",
    "ci_errors_upper = [rmse_ci_upper[i] - rmse_values[i] for i in range(len(rmse_values))]\n",
    "\n",
    "bars = plt.bar(range(len(model_names_plot)), rmse_values, \n",
    "               yerr=[ci_errors, ci_errors_upper], capsize=5, alpha=0.7)\n",
    "plt.xlabel('æ¨¡å‹')\n",
    "plt.ylabel('æµ‹è¯•é›†RMSE')\n",
    "plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯” (RMSE, 95%ç½®ä¿¡åŒºé—´)')\n",
    "plt.xticks(range(len(model_names_plot)), model_names_plot, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ä¸ºæœ€ä½³æ¨¡å‹ç€è‰²\n",
    "best_idx = rmse_values.index(min(rmse_values))\n",
    "bars[best_idx].set_color('green')\n",
    "bars[best_idx].set_alpha(0.9)\n",
    "\n",
    "# å­å›¾2ï¼šMAEå¯¹æ¯”\n",
    "plt.subplot(2, 2, 2)\n",
    "mae_values = summary_df_sorted['mae_value'].tolist()\n",
    "\n",
    "# æå–MAEç½®ä¿¡åŒºé—´\n",
    "mae_ci_lower = []\n",
    "mae_ci_upper = []\n",
    "for mae_str in summary_df_sorted['Test_MAE']:\n",
    "    ci_parts = mae_str.split('[')[1].split(']')[0].split(', ')\n",
    "    mae_ci_lower.append(float(ci_parts[0]))\n",
    "    mae_ci_upper.append(float(ci_parts[1]))\n",
    "\n",
    "mae_ci_errors = [mae_values[i] - mae_ci_lower[i] for i in range(len(mae_values))]\n",
    "mae_ci_errors_upper = [mae_ci_upper[i] - mae_values[i] for i in range(len(mae_values))]\n",
    "\n",
    "bars2 = plt.bar(range(len(model_names_plot)), mae_values, \n",
    "                yerr=[mae_ci_errors, mae_ci_errors_upper], capsize=5, alpha=0.7, color='orange')\n",
    "plt.xlabel('æ¨¡å‹')\n",
    "plt.ylabel('æµ‹è¯•é›†MAE')\n",
    "plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯” (MAE, 95%ç½®ä¿¡åŒºé—´)')\n",
    "plt.xticks(range(len(model_names_plot)), model_names_plot, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "bars2[best_idx].set_color('green')\n",
    "bars2[best_idx].set_alpha(0.9)\n",
    "\n",
    "# å­å›¾3ï¼šMAPEå¯¹æ¯”\n",
    "plt.subplot(2, 2, 3)\n",
    "mape_values = summary_df_sorted['mape_value'].tolist()\n",
    "\n",
    "# æå–MAPEç½®ä¿¡åŒºé—´\n",
    "mape_ci_lower = []\n",
    "mape_ci_upper = []\n",
    "for mape_str in summary_df_sorted['Test_MAPE']:\n",
    "    ci_parts = mape_str.split('[')[1].split('%]')[0].split('%, ')\n",
    "    mape_ci_lower.append(float(ci_parts[0]))\n",
    "    mape_ci_upper.append(float(ci_parts[1]))\n",
    "\n",
    "mape_ci_errors = [mape_values[i] - mape_ci_lower[i] for i in range(len(mape_values))]\n",
    "mape_ci_errors_upper = [mape_ci_upper[i] - mape_values[i] for i in range(len(mape_values))]\n",
    "\n",
    "bars3 = plt.bar(range(len(model_names_plot)), mape_values, \n",
    "                yerr=[mape_ci_errors, mape_ci_errors_upper], capsize=5, alpha=0.7, color='purple')\n",
    "plt.xlabel('æ¨¡å‹')\n",
    "plt.ylabel('æµ‹è¯•é›†MAPE (%)')\n",
    "plt.title('æ¨¡å‹æ€§èƒ½å¯¹æ¯” (MAPE, 95%ç½®ä¿¡åŒºé—´)')\n",
    "plt.xticks(range(len(model_names_plot)), model_names_plot, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "bars3[best_idx].set_color('green')\n",
    "bars3[best_idx].set_alpha(0.9)\n",
    "\n",
    "# å­å›¾4ï¼šæœ€ä½³æ¨¡å‹æ•£ç‚¹å›¾ï¼ˆåŒ¹é…å‚è€ƒå›¾é£æ ¼ï¼‰\n",
    "plt.subplot(2, 2, 4)\n",
    "best_model_name = summary_df_sorted.iloc[0]['Model']\n",
    "y_pred_best = results[best_model_name]['y_pred']\n",
    "y_test_best = results[best_model_name]['y_test']\n",
    "\n",
    "# è®¡ç®—æ‹Ÿåˆçº¿\n",
    "slope, intercept, r_value, p_value, std_err = linregress(y_test_best, y_pred_best)\n",
    "fit_line = intercept + slope * y_test_best\n",
    "\n",
    "# ========== æ ¸å¿ƒä¿®æ”¹ï¼šå…¨å±€å›ºå®šå®½åº¦ç½®ä¿¡åŒºé—´ï¼ˆåŒ¹é…å‚è€ƒå›¾ï¼‰ ==========\n",
    "# è®¡ç®—å…¨å±€è¯¯å·®æ ‡å‡†å·®\n",
    "errors = y_pred_best - y_test_best\n",
    "std_error_global = np.std(errors)\n",
    "ci_95_global = 1.96 * std_error_global  # 95%ç½®ä¿¡åŒºé—´å®½åº¦\n",
    "\n",
    "# ç»˜åˆ¶æ•£ç‚¹å›¾ï¼ˆJeté…è‰²+è‰²æ¡ï¼‰\n",
    "sc = plt.scatter(y_test_best, y_pred_best, c=y_pred_best, cmap='jet', alpha=0.8, s=30)\n",
    "# ç†æƒ³çº¿ï¼ˆç´«è‰²è™šçº¿ï¼Œè´¯ç©¿æ•´ä¸ª0-1åŒºé—´ï¼‰\n",
    "plt.plot([0, 1], [0, 1], 'purple', linestyle='--', linewidth=2, label='ç†æƒ³çº¿ (y=x)')\n",
    "# æ‹Ÿåˆçº¿ï¼ˆçº¢è‰²å®çº¿ï¼‰\n",
    "plt.plot(y_test_best, fit_line, 'red', linewidth=2, \n",
    "         label=f'æ‹Ÿåˆçº¿: y={intercept:.4f}+{slope:.4f}x')\n",
    "\n",
    "# ========== å…¨å±€å›ºå®šå®½åº¦ç½®ä¿¡åŒºé—´ï¼ˆåŒ¹é…å‚è€ƒå›¾ï¼‰ ==========\n",
    "plt.fill_between(y_test_best, \n",
    "                 fit_line - ci_95_global, \n",
    "                 fit_line + ci_95_global, \n",
    "                 color='pink', alpha=0.3, label='95%ç½®ä¿¡åŒºé—´')\n",
    "\n",
    "# æ·»åŠ æŒ‡æ ‡æ ‡æ³¨ï¼ˆåŒ¹é…å‚è€ƒå›¾ä½ç½®å’Œæ ¼å¼ï¼‰\n",
    "r2 = results[best_model_name]['r2']\n",
    "rmse = results[best_model_name]['rmse']\n",
    "mae = results[best_model_name]['mae']\n",
    "mape = results[best_model_name]['mape']  # æ–°å¢\n",
    "plt.text(0.05, 0.95, \n",
    "         f'$R^2={r2:.3f}$\\nRMSE={rmse:.3f}\\nMAE={mae:.3f}\\nMAPE={mape:.1f}%',  # æ–°å¢MAPE\n",
    "         transform=plt.gca().transAxes, \n",
    "         verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "         fontsize=10)\n",
    "\n",
    "# æ·»åŠ è‰²æ¡\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('é¢„æµ‹å€¼', fontsize=10)\n",
    "\n",
    "# è®¾ç½®åæ ‡è½´èŒƒå›´ï¼ˆ0-1ï¼‰\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('è§‚æµ‹å€¼', fontsize=10)\n",
    "plt.ylabel('é¢„æµ‹å€¼', fontsize=10)\n",
    "plt.title(f'æœ€ä½³æ¨¡å‹: {best_model_name}', fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_with_ci.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ æ¨¡å‹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º 'model_comparison_with_ci.png'\")\n",
    "\n",
    "# ============ ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„æ•£ç‚¹å›¾ï¼ˆå®Œå…¨åŒ¹é…å‚è€ƒå›¾é£æ ¼ï¼‰ ============\n",
    "for model_name in results.keys():\n",
    "    y_pred = results[model_name]['y_pred']\n",
    "    y_test_vals = results[model_name]['y_test']\n",
    "    r2 = results[model_name]['r2']\n",
    "    rmse = results[model_name]['rmse']\n",
    "    mae = results[model_name]['mae']\n",
    "    mape = results[model_name]['mape']  # æ–°å¢\n",
    "    \n",
    "    # è®¡ç®—æ‹Ÿåˆçº¿\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(y_test_vals, y_pred)\n",
    "    fit_line = intercept + slope * y_test_vals\n",
    "    \n",
    "    # ========== æ ¸å¿ƒä¿®æ”¹ï¼šå…¨å±€å›ºå®šå®½åº¦ç½®ä¿¡åŒºé—´ï¼ˆåŒ¹é…å‚è€ƒå›¾ï¼‰ ==========\n",
    "    # è®¡ç®—å…¨å±€è¯¯å·®æ ‡å‡†å·®\n",
    "    errors = y_pred - y_test_vals\n",
    "    std_error_global = np.std(errors)\n",
    "    ci_95_global = 1.96 * std_error_global  # 95%ç½®ä¿¡åŒºé—´å®½åº¦\n",
    "    \n",
    "    # åˆ›å»ºå›¾è¡¨ï¼ˆåŒ¹é…å‚è€ƒå›¾å°ºå¯¸ï¼‰\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    \n",
    "    # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼ˆJeté…è‰²+è‰²æ¡ï¼‰\n",
    "    sc = plt.scatter(y_test_vals, y_pred, c=y_pred, cmap='jet', alpha=0.8, s=30)\n",
    "    \n",
    "    # ç†æƒ³çº¿ï¼ˆç´«è‰²è™šçº¿ï¼Œè´¯ç©¿æ•´ä¸ª0-1åŒºé—´ï¼‰\n",
    "    plt.plot([0, 1], [0, 1], 'purple', linestyle='--', linewidth=2, label='ç†æƒ³çº¿ (y=x)')\n",
    "    \n",
    "    # æ‹Ÿåˆçº¿ï¼ˆçº¢è‰²å®çº¿ï¼‰\n",
    "    plt.plot(y_test_vals, fit_line, 'red', linewidth=2, \n",
    "             label=f'æ‹Ÿåˆçº¿: y={intercept:.4f}+{slope:.4f}x')\n",
    "    \n",
    "    # ========== å…¨å±€å›ºå®šå®½åº¦ç½®ä¿¡åŒºé—´ï¼ˆåŒ¹é…å‚è€ƒå›¾ï¼‰ ==========\n",
    "    plt.fill_between(y_test_vals, \n",
    "                     fit_line - ci_95_global, \n",
    "                     fit_line + ci_95_global, \n",
    "                     color='pink', alpha=0.3, label='95%ç½®ä¿¡åŒºé—´')\n",
    "    \n",
    "    # æŒ‡æ ‡æ ‡æ³¨ï¼ˆåŒ¹é…å‚è€ƒå›¾æ ¼å¼ï¼‰\n",
    "    plt.text(0.05, 0.95, \n",
    "             f'$R^2={r2:.3f}$\\nRMSE={rmse:.3f}\\nMAE={mae:.3f}\\nMAPE={mape:.1f}%',  # æ–°å¢MAPE\n",
    "             transform=plt.gca().transAxes, \n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "             fontsize=10)\n",
    "    \n",
    "    # è‰²æ¡\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label('é¢„æµ‹å€¼', fontsize=10)\n",
    "    \n",
    "    # è®¾ç½®åæ ‡è½´èŒƒå›´ï¼ˆ0-1ï¼‰ï¼ŒåŒ¹é…å‚è€ƒå›¾\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # æ ‡ç­¾å’Œæ ‡é¢˜\n",
    "    plt.xlabel('è§‚æµ‹å€¼', fontsize=12)\n",
    "    plt.ylabel('é¢„æµ‹å€¼', fontsize=12)\n",
    "    plt.title(f'{model_name} æ¨¡å‹ - é¢„æµ‹å€¼ vs è§‚æµ‹å€¼', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ä¿å­˜ï¼ˆé«˜åˆ†è¾¨ç‡ï¼‰\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_predictions_scatter.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ“ {model_name} æ•£ç‚¹å›¾å·²ä¿å­˜ä¸º '{model_name}_predictions_scatter.png'\")\n",
    "\n",
    "# ============ ç”Ÿæˆæ‰€æœ‰æ¨¡å‹æ±‡æ€»æ•£ç‚¹å›¾ï¼ˆåŒ¹é…é£æ ¼ï¼‰ ============\n",
    "model_count = len(results)\n",
    "n_rows = (model_count + 1) // 2\n",
    "n_cols = 2 if model_count > 1 else 1\n",
    "\n",
    "plt.figure(figsize=(14, 6 * n_rows))\n",
    "for idx, (model_name, res) in enumerate(results.items()):\n",
    "    y_pred = res['y_pred']\n",
    "    y_test_vals = res['y_test']\n",
    "    r2 = res['r2']\n",
    "    rmse = res['rmse']\n",
    "    mape = res['mape']  # æ–°å¢\n",
    "    \n",
    "    # è®¡ç®—æ‹Ÿåˆçº¿\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(y_test_vals, y_pred)\n",
    "    fit_line = intercept + slope * y_test_vals\n",
    "    \n",
    "    # ========== å…¨å±€å›ºå®šå®½åº¦ç½®ä¿¡åŒºé—´ ==========\n",
    "    errors = y_pred - y_test_vals\n",
    "    std_error_global = np.std(errors)\n",
    "    ci_95_global = 1.96 * std_error_global\n",
    "    \n",
    "    # åˆ›å»ºå­å›¾\n",
    "    plt.subplot(n_rows, n_cols, idx + 1)\n",
    "    \n",
    "    # ç»˜åˆ¶æ•£ç‚¹å›¾\n",
    "    sc = plt.scatter(y_test_vals, y_pred, c=y_pred, cmap='jet', alpha=0.8, s=20)\n",
    "    # ç†æƒ³çº¿ï¼ˆè´¯ç©¿0-1ï¼‰\n",
    "    plt.plot([0, 1], [0, 1], 'purple', linestyle='--', linewidth=2)\n",
    "    # æ‹Ÿåˆçº¿\n",
    "    plt.plot(y_test_vals, fit_line, 'red', linewidth=2)\n",
    "    # å…¨å±€ç½®ä¿¡åŒºé—´\n",
    "    plt.fill_between(y_test_vals, fit_line - ci_95_global, fit_line + ci_95_global, color='pink', alpha=0.3)\n",
    "    \n",
    "    # æŒ‡æ ‡æ ‡æ³¨\n",
    "    plt.text(0.05, 0.95, f'$R^2={r2:.3f}$\\nRMSE={rmse:.3f}\\nMAPE={mape:.1f}%',  # æ–°å¢MAPE\n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), fontsize=9)\n",
    "    \n",
    "    # è‰²æ¡ï¼ˆä»…æœ€åä¸€ä¸ªå­å›¾ï¼‰\n",
    "    if idx == len(results) - 1:\n",
    "        cbar = plt.colorbar(sc, ax=plt.gca())\n",
    "        cbar.set_label('é¢„æµ‹å€¼', fontsize=9)\n",
    "    \n",
    "    # è®¾ç½®åæ ‡è½´èŒƒå›´\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # æ ‡ç­¾å’Œæ ‡é¢˜\n",
    "    plt.xlabel('è§‚æµ‹å€¼', fontsize=10)\n",
    "    plt.ylabel('é¢„æµ‹å€¼', fontsize=10)\n",
    "    plt.title(f'{model_name}', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_models_predictions_scatter.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ æ‰€æœ‰æ¨¡å‹æ•£ç‚¹å›¾æ±‡æ€»å·²ä¿å­˜ä¸º 'all_models_predictions_scatter.png'\")\n",
    "\n",
    "# 9.2 ç»Ÿè®¡æ£€éªŒå¯è§†åŒ–\n",
    "if 't_test_df' in locals() and not t_test_df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # æå–på€¼\n",
    "    comparisons = t_test_df['Comparison'].tolist()\n",
    "    p_values = t_test_df['p_value_one_sided'].tolist()  # ä½¿ç”¨å•ä¾§på€¼\n",
    "    \n",
    "    # åˆ›å»ºé¢œè‰²æ˜ å°„ï¼ˆæ ¹æ®æ˜¾è‘—æ€§ï¼‰\n",
    "    colors = []\n",
    "    for p in p_values:\n",
    "        if p < 0.001:\n",
    "            colors.append('red')\n",
    "        elif p < 0.01:\n",
    "            colors.append('orange')\n",
    "        elif p < 0.05:\n",
    "            colors.append('yellow')\n",
    "        else:\n",
    "            colors.append('gray')\n",
    "    \n",
    "    # ç»˜åˆ¶på€¼\n",
    "    bars = plt.barh(range(len(comparisons)), -np.log10(p_values), color=colors)\n",
    "    plt.axvline(x=-np.log10(0.05), color='blue', linestyle='--', alpha=0.7, label='p=0.05')\n",
    "    plt.axvline(x=-np.log10(0.01), color='green', linestyle='--', alpha=0.7, label='p=0.01')\n",
    "    plt.axvline(x=-np.log10(0.001), color='red', linestyle='--', alpha=0.7, label='p=0.001')\n",
    "    \n",
    "    plt.xlabel('-logâ‚â‚€(på€¼)')\n",
    "    plt.title('ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ (-logâ‚â‚€(på€¼)ï¼Œè¶Šé«˜è¶Šæ˜¾è‘—)')\n",
    "    plt.yticks(range(len(comparisons)), comparisons)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('statistical_significance_plot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"âœ“ ç»Ÿè®¡æ˜¾è‘—æ€§å›¾å·²ä¿å­˜ä¸º 'statistical_significance_plot.png'\")\n",
    "\n",
    "# ============ 10. ä¿å­˜æ‰€æœ‰ç»“æœ ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ä¿å­˜æ‰€æœ‰ç»“æœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "output_file = 'statistical_analysis_full_results.xlsx'\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    # å·¥ä½œè¡¨1: æ€§èƒ½æ€»ç»“ï¼ˆåŒ…å«MAEå’ŒMAPEï¼‰\n",
    "    summary_export_df = summary_df_sorted.copy()\n",
    "    summary_export_df = summary_export_df[[\n",
    "        'Model', 'Test_RMSE', 'Test_MAE', 'Test_MAPE', 'Test_R2',\n",
    "        'CV_RMSE_mean', 'CV_RMSE_std', 'CV_RMSE_CI_lower', 'CV_RMSE_CI_upper'\n",
    "    ]]\n",
    "    summary_export_df.to_excel(writer, sheet_name='Performance_Summary', index=False)\n",
    "    \n",
    "    # å·¥ä½œè¡¨2: è¯¦ç»†äº¤å‰éªŒè¯ç»“æœ\n",
    "    cv_details = []\n",
    "    for name, res in results.items():\n",
    "        for fold_idx, score in enumerate(res['cv_rmse_scores']):\n",
    "            cv_details.append({\n",
    "                'Model': name,\n",
    "                'Fold': fold_idx + 1,\n",
    "                'RMSE': score\n",
    "            })\n",
    "    pd.DataFrame(cv_details).to_excel(writer, sheet_name='CV_Details', index=False)\n",
    "    \n",
    "    # å·¥ä½œè¡¨3: é¢„æµ‹å€¼\n",
    "    predictions_data = []\n",
    "    for model_name in results.keys():\n",
    "        y_pred = results[model_name]['y_pred']\n",
    "        y_test_vals = results[model_name]['y_test']\n",
    "        mape = results[model_name]['mape']\n",
    "        \n",
    "        for i in range(len(y_pred)):\n",
    "            error = y_test_vals[i] - y_pred[i]\n",
    "            absolute_error = abs(error)\n",
    "            squared_error = error ** 2\n",
    "            percentage_error = abs(error / (y_test_vals[i] + 1e-10)) * 100 if y_test_vals[i] != 0 else 0\n",
    "            \n",
    "            predictions_data.append({\n",
    "                'Model': model_name,\n",
    "                'Sample_ID': i,\n",
    "                'True_Value': y_test_vals[i],\n",
    "                'Predicted_Value': y_pred[i],\n",
    "                'Error': error,\n",
    "                'Absolute_Error': absolute_error,\n",
    "                'Squared_Error': squared_error,\n",
    "                'Percentage_Error': percentage_error\n",
    "            })\n",
    "    pd.DataFrame(predictions_data).to_excel(writer, sheet_name='Predictions', index=False)\n",
    "    \n",
    "    # å·¥ä½œè¡¨4: ç»Ÿè®¡æ£€éªŒç»“æœ\n",
    "    if 't_test_df' in locals():\n",
    "        t_test_df.to_excel(writer, sheet_name='Statistical_Tests', index=False)\n",
    "    \n",
    "    # å·¥ä½œè¡¨5: æ¨¡å‹å‚æ•°\n",
    "    params_data = []\n",
    "    for name, res in results.items():\n",
    "        params_data.append({\n",
    "            'Model': name,\n",
    "            'Best_Parameters': str(res['best_params']),\n",
    "            'Test_RMSE': res['rmse'],\n",
    "            'Test_MAE': res['mae'],\n",
    "            'Test_MAPE': res['mape'],\n",
    "            'Test_R2': res['r2']\n",
    "        })\n",
    "    pd.DataFrame(params_data).to_excel(writer, sheet_name='Parameters', index=False)\n",
    "    \n",
    "    # å·¥ä½œè¡¨6: VIFåˆ†æç»“æœ\n",
    "    if 'vif_results' in locals():\n",
    "        vif_results.to_excel(writer, sheet_name='VIF_Analysis', index=False)\n",
    "    \n",
    "    # æ–°å¢å·¥ä½œè¡¨7: æ±‡æ€»ç»Ÿè®¡\n",
    "    summary_stats = []\n",
    "    for name, res in results.items():\n",
    "        summary_stats.append({\n",
    "            'Model': name,\n",
    "            'RMSE': res['rmse'],\n",
    "            'MAE': res['mae'],\n",
    "            'MAPE': res['mape'],\n",
    "            'R2': res['r2'],\n",
    "            'CV_RMSE_Mean': np.mean(res['cv_rmse_scores']),\n",
    "            'CV_RMSE_Std': np.std(res['cv_rmse_scores'])\n",
    "        })\n",
    "    pd.DataFrame(summary_stats).to_excel(writer, sheet_name='Summary_Stats', index=False)\n",
    "\n",
    "print(f\"âœ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° '{output_file}'\")\n",
    "\n",
    "# ============ 11. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š ============\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç»Ÿè®¡åˆ†ææŠ¥å‘Š\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š\n",
    "report_lines = []\n",
    "report_lines.append(\"=\"*80)\n",
    "report_lines.append(\"                    æ¨¡å‹æ¯”è¾ƒç»Ÿè®¡æŠ¥å‘Š\")\n",
    "report_lines.append(\"=\"*80)\n",
    "report_lines.append(f\"æ•°æ®é›†: {df.shape[0]} æ ·æœ¬, {df.shape[1]} ç‰¹å¾\")\n",
    "report_lines.append(f\"ç›®æ ‡å˜é‡: {target_col}\")\n",
    "report_lines.append(f\"æ¯”è¾ƒæ¨¡å‹æ•°: {len(results)}\")\n",
    "report_lines.append(f\"è¯„ä¼°æŒ‡æ ‡: RMSE, MAE, MAPE, RÂ²\")\n",
    "report_lines.append(f\"ç½®ä¿¡åŒºé—´: ä½¿ç”¨Bootstrapæ–¹æ³•è®¡ç®— (n=1000)\")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "# æœ€ä½³æ¨¡å‹ä¿¡æ¯\n",
    "if len(results) > 0:\n",
    "    best_model_info = summary_df_sorted.iloc[0]\n",
    "    report_lines.append(\"ğŸ† æœ€ä½³æ¨¡å‹æ€§èƒ½æ€»ç»“:\")\n",
    "    report_lines.append(\"-\" * 80)\n",
    "    report_lines.append(f\"  æ¨¡å‹: {best_model_info['Model']}\")\n",
    "    report_lines.append(f\"  æµ‹è¯•é›†RMSE: {best_model_info['Test_RMSE']}\")\n",
    "    report_lines.append(f\"  æµ‹è¯•é›†MAE: {best_model_info['Test_MAE']}\")\n",
    "    report_lines.append(f\"  æµ‹è¯•é›†MAPE: {best_model_info['Test_MAPE']}\")\n",
    "    report_lines.append(f\"  æµ‹è¯•é›†RÂ²: {best_model_info['Test_R2']}\")\n",
    "    report_lines.append(f\"  äº¤å‰éªŒè¯RMSE: {best_model_info['CV_RMSE_mean']:.4f} \"\n",
    "                       f\"[{best_model_info['CV_RMSE_CI_lower']:.4f}, \"\n",
    "                       f\"{best_model_info['CV_RMSE_CI_upper']:.4f}]\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "# å¤šé‡å…±çº¿æ€§æ€»ç»“\n",
    "if 'vif_results' in locals():\n",
    "    high_vif = len(vif_results[vif_results[\"VIF\"] >= 10])\n",
    "    moderate_vif = len(vif_results[(vif_results[\"VIF\"] >= 5) & (vif_results[\"VIF\"] < 10)])\n",
    "    \n",
    "    report_lines.append(\"ğŸ“Š å¤šé‡å…±çº¿æ€§åˆ†æ:\")\n",
    "    report_lines.append(f\"  ä¸¥é‡å…±çº¿æ€§ç‰¹å¾ (VIF â‰¥ 10): {high_vif}\")\n",
    "    report_lines.append(f\"  ä¸­åº¦å…±çº¿æ€§ç‰¹å¾ (5 â‰¤ VIF < 10): {moderate_vif}\")\n",
    "    \n",
    "    if high_vif > 0:\n",
    "        report_lines.append(\"  âš ï¸  å»ºè®®æ£€æŸ¥é«˜VIFç‰¹å¾:\")\n",
    "        for _, row in vif_results[vif_results[\"VIF\"] >= 10].head(3).iterrows():\n",
    "            report_lines.append(f\"    - {row['Feature']}: VIF = {row['VIF']:.2f}\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "# ç»Ÿè®¡æ˜¾è‘—æ€§æ€»ç»“\n",
    "if 't_test_df' in locals():\n",
    "    sig_count_005 = sum(t_test_df['significant_0.05'])\n",
    "    sig_count_001 = sum(t_test_df['significant_0.01'])\n",
    "    sig_count_0001 = sum(t_test_df['significant_0.001'])\n",
    "    \n",
    "    report_lines.append(\"ğŸ“ˆ ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ:\")\n",
    "    report_lines.append(f\"  é…å¯¹tæ£€éªŒæ˜¾è‘—æ•°é‡ (p < 0.05): {sig_count_005}/{len(t_test_df)}\")\n",
    "    report_lines.append(f\"  é…å¯¹tæ£€éªŒæ˜¾è‘—æ•°é‡ (p < 0.01): {sig_count_001}/{len(t_test_df)}\")\n",
    "    report_lines.append(f\"  é…å¯¹tæ£€éªŒæ˜¾è‘—æ•°é‡ (p < 0.001): {sig_count_0001}/{len(t_test_df)}\")\n",
    "    \n",
    "    if sig_count_005 > 0:\n",
    "        report_lines.append(\"  æ˜¾è‘—ä¼˜äºåŸºå‡†çš„æ¨¡å‹:\")\n",
    "        for _, row in t_test_df[t_test_df['significant_0.05']].iterrows():\n",
    "            stars = \"***\" if row['significant_0.001'] else \"**\" if row['significant_0.01'] else \"*\" if row['significant_0.05'] else \"\"\n",
    "            report_lines.append(f\"    - {row['Comparison']} {stars} (d={row['cohens_d']:.3f})\")\n",
    "\n",
    "# ä¿å­˜æŠ¥å‘Š\n",
    "report_text = \"\\n\".join(report_lines)\n",
    "with open('statistical_analysis_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(report_text)\n",
    "print(f\"\\nâœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° 'statistical_analysis_report.txt'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ç»Ÿè®¡åˆ†æå®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(\"ç”Ÿæˆçš„æ–‡ä»¶:\")\n",
    "print(f\"  1. {output_file} - æ‰€æœ‰è¯¦ç»†ç»“æœ\")\n",
    "print(f\"  2. vif_analysis_results.xlsx - å¤šé‡å…±çº¿æ€§åˆ†æ\")\n",
    "print(f\"  3. model_comparison_with_ci.png - æ¨¡å‹å¯¹æ¯”å›¾ï¼ˆåŒ…å«RMSE/MAE/MAPEï¼‰\")\n",
    "print(f\"  4. statistical_significance_plot.png - ç»Ÿè®¡æ˜¾è‘—æ€§å›¾\")\n",
    "print(f\"  5. statistical_analysis_report.txt - åˆ†ææŠ¥å‘Š\")\n",
    "print(f\"  6. all_models_predictions_scatter.png - æ‰€æœ‰æ¨¡å‹æ•£ç‚¹å›¾æ±‡æ€»\")\n",
    "for model_name in results.keys():\n",
    "    print(f\"  7. {model_name}_predictions_scatter.png - {model_name}æ•£ç‚¹å›¾ï¼ˆåŒ…å«MAPEï¼‰\")\n",
    "if os.path.exists('vif_analysis.png'):\n",
    "    print(f\"  {8 + len(results) if len(results) > 0 else 7}. vif_analysis.png - VIFå¯è§†åŒ–å›¾\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83154c0-32e9-4d88-b00c-7a9b94650116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
